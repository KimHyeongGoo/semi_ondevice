import psycopg2
import re
import time
from datetime import datetime, timedelta
import os
import pandas as pd
import numpy as np
import joblib
import xgboost as xgb

selected_cols = ['PPExecStepID', 'MFC1_N2-1', 'MFC2_N2-2', 'MFC3_N2-3', 'MFC4_N2-4', 'MFC26_F.PWR', 'MFC27_L.POS', 'MFC28_R.POS', 'MFC7_DCS', 'MFC8_NH3', 'MFC9_F2', 'APC Valve Value (Angle)', 'VG11 Press value', 'VG12 Press value', 'VG13 Press value', 'Temp_Act_U', 'Temp_Act_CU', 'Temp_Act_C', 'Temp_Act_CL', 'Temp_Act_L', 'ValveAct_2:2', 'ValveAct_3:3', 'ValveAct_4:4', 'ValveAct_5:5', 'ValveAct_9:9', 'ValveAct_12:12', 'ValveAct_14:14', 'ValveAct_16:16', 'ValveAct_26:26', 'ValveAct_28:28', 'ValveAct_29:29', 'ValveAct_60:71', 'ValveAct_63:75', 'ValveAct_73:83', 'ValveAct_80:DPO', 'ValveAct_89:RF', 'ValveAct_90:PST']
step_reverse_dict = {'END': 2, 'STANDBY': 0, 'START': 1, 'B.UP': 17, 'WAIT': 3, 'S.P-1': 74, 'S.P-2': 75, 'R.UP1': 25, 'STAB1': 22, 'S.P-3': 76, 'M.P-3': 81, 'L.CHK': 72, 'PREPRG1': 44, 'EVAC1': 99, 'EVAC2': 100, 'N-EVA1': 111, 'CLOSE1': 128, 'SI-FL1': 119, 'SI-EVA1': 117, 'CHANGE': 152, 'N-PRE1': 113, 'N-FL1': 115, 'N-FL2': 116, 'pre-NH3P': 110, 'DEPO1': 49, 'post_NH3P': 135, 'N2PRG1': 103, 'SI-EVA4': 149, 'A.VAC2': 85, 'A.PRG2': 90, 'A.VAC1': 84, 'A.PRG1': 89, 'N2PRG2': 104, 'N2PRG3': 105, 'A.VAC3': 86, 'A.PRG3': 91, 'A.VAC4': 87, 'A.PRG4': 92, 'CYCLE1': 130, 'A.PRG5': 93, 'R.DOWN1': 31, 'B.FILL1': 94, 'B.FILL2': 95, 'B.FILL3': 96, 'B.FILL4': 97, 'B.FILL5': 98, 'B.DOWN': 18, 'None': 0, 'nan': 0, 'NaN': 0, 'null': 0, 'NULL': 0, 'IDLE': 0}

def fetch_trace_data(start_ts, end_ts, start_table, end_table):
    conn = psycopg2.connect(
        dbname="postgres",
        user="keti",
        password="keti1234!",
        host="localhost",
        port=5432
    )

    all_data = []

    colnames = ', '.join([f'"{col}"' for col in ["Timestamp"] + selected_cols])

    start_date = datetime.strptime(start_table.replace("rawdata", ""), "%Y%m%d")
    end_date = datetime.strptime(end_table.replace("rawdata", ""), "%Y%m%d")

    if start_table == end_table:
        # ‚úÖ Îã®Ïùº ÌÖåÏù¥Î∏î Ï≤òÎ¶¨
        query = f'''
            SELECT {colnames}
            FROM "{start_table}"
            WHERE "Timestamp" BETWEEN %s AND %s
        '''
        try:
            df = pd.read_sql(query, conn, params=(start_ts, end_ts))
            all_data.append(df)
        except Exception as e:
            print(f"‚ùó {start_table} Ï°∞Ìöå Ïã§Ìå®: {e}")
    else:
        current_date = start_date
        while current_date <= end_date:
            table_name = f'rawdata{current_date.strftime("%Y%m%d")}'
            print(f"üìò ÌÖåÏù¥Î∏î Ï°∞Ìöå: {table_name}")

            # Ï°∞Í±¥ Î∂ÑÍ∏∞: ÏãúÏûë/Ï§ëÍ∞Ñ/Ï¢ÖÎ£å ÌÖåÏù¥Î∏î
            if current_date == start_date:
                where_clause = 'WHERE "Timestamp" >= %s'
                params = (start_ts,)
            elif current_date == end_date:
                where_clause = 'WHERE "Timestamp" <= %s'
                params = (end_ts,)
            else:
                where_clause = ''
                params = ()

            try:
                query = f'''
                    SELECT {colnames}
                    FROM "{table_name}"
                    {where_clause}
                '''
                df = pd.read_sql(query, conn, params=params)
                all_data.append(df)
            except Exception as e:
                print(f"‚ùó {table_name} Ï°∞Ìöå Ïã§Ìå®: {e}")

            current_date += timedelta(days=1)

    conn.close()

    # Îëê Í∞ú Ïù¥ÏÉÅ ÌÖåÏù¥Î∏îÏùÑ ÏÇ¨Ïö©Ìï† Í≤ΩÏö∞ concat
    final_df = pd.concat(all_data, ignore_index=True)
    final_df.sort_values(["Timestamp"], inplace=True)
    final_df.drop(columns=['Timestamp'], inplace=True)
    final_df.dropna(inplace=True)
    #print(final_df)
    final_df.reset_index(drop=True, inplace=True)
    return final_df



def predict_thickness(start_ts, end_ts, start_table, end_table):
    #print(start_ts, end_ts, start_table, end_table)
    data = fetch_trace_data(start_ts, end_ts, start_table, end_table)
    #print(data)
    
    X_all = []
    data = data[selected_cols]
    tdf = data[(data['PPExecStepID'] >= 100) & (data['PPExecStepID'] < 160)]
    if len(tdf) <= 300:
        return []
    end_i = tdf.index[-1]+1
    start_i = tdf.index[0]
    data = data.iloc[start_i : end_i]
    data.reset_index(drop=False, inplace=True)
    start_index_value = data['index'].iloc[0]
    data['seconds'] = data['index'] - start_index_value
    data.drop(columns='index', inplace=True)

    # --- [Ï§ëÏöî] ÏûÖÎ†• ÌîºÏ≤ò ÏÉùÏÑ± ---
    features = []
    stats = data.agg(['mean', 'std', 'min', 'max', 'median'])
    features.extend(stats.values.flatten())

    # --- Append to list ---
    X_all.append(features)

    # --- ÏµúÏ¢Ö DataFrame Î≥ÄÌôò ---
    X_all = np.array(X_all)
    #print(f" Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¨Í∏∞: {X_all.shape}")
    
    dtest = xgb.DMatrix(X_all)

    # Í≤ΩÎ°ú ÏÑ§Ï†ï
    model_dir = './xgb_model'
    model_num = len([f for f in os.listdir(model_dir) if f.endswith('.json')])

    # best_iters Î°úÎî©
    best_iters = joblib.load(os.path.join(model_dir, "best_iters.pkl"))

    # Î™®Îç∏ Î°úÎî©
    loaded_models = []
    for i in range(model_num):
        model = xgb.Booster()
        model.load_model(os.path.join(model_dir, f"xgb_model_{i}.json"))
        loaded_models.append(model)
        
    # === Îç∞Ïù¥ÌÑ∞Î°ú ÏòàÏ∏° ===
    y_preds = []
    for i,model in enumerate(loaded_models):
        y_pred_i = model.predict(dtest, iteration_range=(0, best_iters[i] + 1))
        y_preds.append(y_pred_i)

    # (45, N) ‚Üí (N, 45)Î°ú transpose
    y_pred = np.array(y_preds).T
    ret = []
    for thicks in list(y_pred[0]):
        ret.append(float(thicks))
    return ret
    
    
def print_existing_trace_info():
    """Ïã§Ìñâ Ï†ÑÏóê ÏßÄÍ∏àÍπåÏßÄ Ï†ÄÏû•Îêú Î™®Îì† Í≥µÏ†ï Íµ¨Í∞Ñ Ï∂úÎ†• (Ïò§ÎûòÎêú Ïàú)"""
    conn = psycopg2.connect(
        dbname="postgres",
        user="keti",
        password="keti1234!",
        host="localhost",
        port=5432
    )
    cur = conn.cursor()

    # trace_info ÌÖåÏù¥Î∏îÏù¥ ÏóÜÏùÑ ÏàòÎèÑ ÏûàÏúºÎØÄÎ°ú CREATE Î®ºÏ†Ä
    # thickness_1 ~ thickness_45ÍπåÏßÄ REAL Ïª¨Îüº Ï∂îÍ∞Ä
    thickness_cols_sql = ',\n    '.join([f'thickness_{i+1} REAL' for i in range(45)])

    cur.execute(f"""
        CREATE TABLE IF NOT EXISTS trace_info (
            start_time TIMESTAMP PRIMARY KEY,
            end_time TIMESTAMP,
            start_table TEXT,
            end_table TEXT,
            {thickness_cols_sql}
        );
    """)

    # Ï†ÄÏû•Îêú Î™®Îì† Í≥µÏ†ï Íµ¨Í∞Ñ Ï∂úÎ†•
    cur.execute("""
        SELECT start_time, end_time, start_table, end_table
        FROM trace_info
        ORDER BY start_time ASC;
    """)
    rows = cur.fetchall()

    if not rows:
        print("üìÇ Ï†ÄÏû•Îêú Í≥µÏ†ï Ïù¥Î†•Ïù¥ ÏóÜÏäµÎãàÎã§.")
    else:
        print(f"\nüìÑ ÏßÄÍ∏àÍπåÏßÄ Ï†ÄÏû•Îêú Í≥µÏ†ï Ï†ïÎ≥¥ ({len(rows)}Í±¥):")
        for idx, (start, end, s_tbl, e_tbl) in enumerate(rows, 1):
            print(f"  {idx:03d}. {start} ~ {end} ({s_tbl} ‚Üí {e_tbl})")

    cur.close()
    conn.close()
    
def insert_trace_info_with_thickness(cur, start_time, end_time, start_table, end_table, thicknesses):
    assert len(thicknesses) == 45, "thicknesses must contain exactly 45 values"

    # Ïª¨ÎüºÎ™Ö ÎèôÏ†Å ÏÉùÏÑ±
    thickness_cols = [f"thickness_{i+1}" for i in range(45)]

    # Ï†ÑÏ≤¥ Ïª¨Îüº
    columns = ["start_time", "end_time", "start_table", "end_table"] + thickness_cols
    placeholders = ', '.join(['%s'] * len(columns))
    colnames = ', '.join(columns)

    sql = f"""
        INSERT INTO trace_info ({colnames})
        VALUES ({placeholders})
        ON CONFLICT (start_time) DO NOTHING;
    """
    values = [start_time, end_time, start_table, end_table] + thicknesses
    cur.execute(sql, values)



def extract_process_ranges_incrementally():
    conn = psycopg2.connect(
        dbname="postgres",
        user="keti",
        password="keti1234!",
        host="localhost",
        port=5432
    )
    cur = conn.cursor()

    # 1. trace_info ÌÖåÏù¥Î∏î ÏÉùÏÑ± (ÏµúÏ¥à 1Ìöå)
    # thickness_1 ~ thickness_45ÍπåÏßÄ REAL Ïª¨Îüº Ï∂îÍ∞Ä
    thickness_cols_sql = ',\n    '.join([f'thickness_{i+1} REAL' for i in range(45)])

    cur.execute(f"""
        CREATE TABLE IF NOT EXISTS trace_info (
            start_time TIMESTAMP PRIMARY KEY,
            end_time TIMESTAMP,
            start_table TEXT,
            end_table TEXT,
            {thickness_cols_sql}
        );
    """)

    # 2. ÎßàÏßÄÎßâ Ï†ÄÏû•Îêú Í≥µÏ†ï end_time Ï°∞Ìöå
    cur.execute("SELECT MAX(end_time) FROM trace_info;")
    result = cur.fetchone()
    last_end_time = result[0] if result and result[0] else None

    if last_end_time:
        print(f"üìå ÎßàÏßÄÎßâ Í≥µÏ†ï Ï¢ÖÎ£åÏãúÍ∞Å: {last_end_time}")
        last_date = int(last_end_time.strftime("%Y%m%d"))
    else:
        print("üìå Ïù¥Ï†Ñ Í≥µÏ†ï Í∏∞Î°ù ÏóÜÏùå. Ï†ÑÏ≤¥ ÌÖåÏù¥Î∏î ÌÉêÏÉâ ÏãúÏûë")
        last_date = 0

    # 3. ÌÖåÏù¥Î∏î Î™©Î°ù Ï§ë Ïù¥ÌõÑ ÎÇ†ÏßúÎßå Ï≤òÎ¶¨
    cur.execute("""
        SELECT table_name
        FROM information_schema.tables
        WHERE table_schema = 'public'
        AND table_name ~ '^rawdata\\d{8}$';
    """)
    tables = [t[0] for t in cur.fetchall()]
    tables_filtered = sorted([
        t for t in tables if int(t.replace("rawdata", "")) >= last_date
    ], key=lambda x: int(x.replace("rawdata", "")))

    # ÏÉÅÌÉú Î≥ÄÏàò
    current_proc = None
    last_ts = None
    last_table = None

    for table in tables_filtered:
        print(f"üìò Ï≤òÎ¶¨ Ï§ë: {table}")
        query = f"""
            SELECT "Timestamp", "ProcessRecipeStepName"
            FROM "{table}"
            WHERE "ProcessRecipeStepName" IS NOT NULL
            ORDER BY "Timestamp" ASC;
        """
        cur.execute(query)
        rows = cur.fetchall()

        for ts, step in rows:
            # ÎßàÏßÄÎßâ Ï≤òÎ¶¨Îêú Ïù¥ÌõÑÎ∂ÄÌÑ∞Îßå
            if last_end_time and ts <= last_end_time:
                continue

            step = step.strip().upper() if step else ""

            if current_proc is None:
                if step in ("STANDBY", "START"):
                    current_proc = {
                        "start_time": ts,
                        "start_table": table
                    }
            else:
                if step == "END":
                    duration = ts - current_proc["start_time"]
                    if duration >= timedelta(hours=1):
                        thicknesses = predict_thickness(current_proc["start_time"], ts, current_proc["start_table"], table)
                        if len(thicknesses) == 0:
                            thicknesses = [0 for _ in range(45)]
                        insert_trace_info_with_thickness(cur, current_proc["start_time"], ts, current_proc["start_table"], table, thicknesses)
                        print(current_proc["start_time"], ts, thicknesses, '\n')
                    current_proc = None
                elif step in ("IDLE", "", "NAN", "NULL"):
                    if last_ts:
                        duration = last_ts - current_proc["start_time"]
                        if duration >= timedelta(hours=1):
                            thicknesses = predict_thickness(current_proc["start_time"], last_ts, current_proc["start_table"], last_table)
                        if len(thicknesses) == 0:
                            thicknesses = [0 for _ in range(45)]
                            insert_trace_info_with_thickness(cur, current_proc["start_time"], last_ts, current_proc["start_table"], last_table, thicknesses)
                            print(current_proc["start_time"], last_ts, thicknesses, '\n')
                        current_proc = None
                elif last_ts:
                    gap = ts - last_ts
                    if gap >= timedelta(hours=1):
                        duration = last_ts - current_proc["start_time"]
                        if duration >= timedelta(hours=1):
                            thicknesses = predict_thickness(current_proc["start_time"], last_ts, current_proc["start_table"], last_table)
                        if len(thicknesses) == 0:
                            thicknesses = [0 for _ in range(45)]
                            insert_trace_info_with_thickness(cur, current_proc["start_time"], last_ts, current_proc["start_table"], last_table, thicknesses)
                            print(f"‚ö†Ô∏è Ï§ëÎã® Í∞êÏßÄ ‚Üí Ï†ÄÏû•Îê®: {current_proc['start_time']} ~ {last_ts}", thicknesses, '\n')
                        else:
                            print(f"‚ö†Ô∏è Ï§ëÎã® Í∞êÏßÄ ‚Üí Î¨¥ÏãúÎê®(1ÏãúÍ∞Ñ ÎØ∏Îßå): {current_proc['start_time']} ~ {last_ts}\n")
                        current_proc = None  # ÌòÑÏû¨ Í≥µÏ†ï Ï¢ÖÎ£å Ï≤òÎ¶¨
            last_ts = ts
            last_table = table

    conn.commit()
    cur.close()
    conn.close()
    print("‚úÖ Ïã†Í∑ú Í≥µÏ†ï Íµ¨Í∞Ñ Ï∂îÏ∂ú ÏôÑÎ£å")

def drop_trace_and_proc_tables():
    conn = psycopg2.connect(
        dbname="postgres",
        user="keti",
        password="keti1234!",
        host="localhost",
        port=5432
    )
    cur = conn.cursor()

    # ÌÖåÏù¥Î∏î ÏÇ≠Ï†ú
    for table in ["proc_info", "trace_info"]:
        try:
            cur.execute(f'DROP TABLE IF EXISTS {table} CASCADE;')
            print(f"‚úÖ ÌÖåÏù¥Î∏î ÏÇ≠Ï†úÎê®: {table}")
        except Exception as e:
            print(f"‚ùå ÏÇ≠Ï†ú Ïã§Ìå®: {table} ‚Üí {e}")

    conn.commit()
    cur.close()
    conn.close()
    
# üïí 30Î∂Ñ Í∞ÑÍ≤© Î£®ÌîÑ
if __name__ == '__main__':
    #drop_trace_and_proc_tables()
    print_existing_trace_info()  
    try:
        while True:
            extract_process_ranges_incrementally()
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]  30Î∂Ñ ÌõÑ Ïû¨Ïã§Ìñâ ÎåÄÍ∏∞ Ï§ë...\n")
            time.sleep(1800)
    except KeyboardInterrupt:
        print("\nüõë ÏàòÎèô Ï¢ÖÎ£åÎê®.")
